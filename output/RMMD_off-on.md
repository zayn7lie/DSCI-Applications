### Train

```
Origin: 1000 = 20 * 50 -> 2000 = 40 * 50 

K-fold: 18 * 50 + 36 * 50 -> 4 * 50 

Epoch: 1 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.574847 MAX=0.927992 MIN=0.379623
- [18/18] Loss: AVG=0.526421 MAX=0.868764 MIN=0.354660
Epoch: 1 Loss: 0.5506337599621879 MMD: 1.5985845915145345 BCE: 0.39077530635727775 

Epoch: 2 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.389227 MAX=0.464890 MIN=0.337680
- [18/18] Loss: AVG=0.438845 MAX=0.685943 MIN=0.297018
Epoch: 2 Loss: 0.4140361332231098 MMD: 0.9854547282059988 BCE: 0.31549066139592064 

Epoch: 3 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.400884 MAX=0.807343 MIN=0.312894
- [18/18] Loss: AVG=0.444974 MAX=0.779619 MIN=0.269128
Epoch: 3 Loss: 0.4229292869567871 MMD: 1.1507051727837987 BCE: 0.30785877092017067 

Epoch: 4 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.455854 MAX=0.735224 MIN=0.312183
- [18/18] Loss: AVG=0.461907 MAX=0.866744 MIN=0.322728
Epoch: 4 Loss: 0.45888027714358437 MMD: 1.566679014099969 BCE: 0.30221237738927204 

Epoch: 5 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.372931 MAX=0.483593 MIN=0.277931
- [18/18] Loss: AVG=0.435339 MAX=0.635740 MIN=0.290551
Epoch: 5 Loss: 0.4041345483726925 MMD: 1.0647713326745563 BCE: 0.29765741527080536 

Epoch: 6 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.389287 MAX=0.556436 MIN=0.298746
- [18/18] Loss: AVG=0.461652 MAX=0.797858 MIN=0.298364
Epoch: 6 Loss: 0.4254694663816028 MMD: 1.3438349117835362 BCE: 0.29108597503768074 

Epoch: 7 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.430072 MAX=0.597166 MIN=0.270185
- [18/18] Loss: AVG=0.390110 MAX=0.554225 MIN=0.311599
Epoch: 7 Loss: 0.4100911617279053 MMD: 1.189596684442626 BCE: 0.29113148897886276 

Epoch: 8 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.305949 MAX=0.337993 MIN=0.258451
- [18/18] Loss: AVG=0.399497 MAX=0.523522 MIN=0.297649
Epoch: 8 Loss: 0.3527231630351808 MMD: 0.6788406943281492 BCE: 0.28483909368515015 

Epoch: 9 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.366427 MAX=0.455271 MIN=0.291706
- [18/18] Loss: AVG=0.363961 MAX=0.663504 MIN=0.272897
Epoch: 9 Loss: 0.36519399450884926 MMD: 0.858393146759934 BCE: 0.27935468322700924 

Epoch: 10 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.373269 MAX=0.837715 MIN=0.288071
- [18/18] Loss: AVG=0.496223 MAX=1.080696 MIN=0.265873
Epoch: 10 Loss: 0.43474603858258987 MMD: 1.6336942174368434 BCE: 0.2713766098022461 

Epoch: 11 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.349298 MAX=0.699139 MIN=0.265069
- [18/18] Loss: AVG=0.358491 MAX=0.494450 MIN=0.260333
Epoch: 11 Loss: 0.3538944489426083 MMD: 0.8429257497191429 BCE: 0.26960187156995136 

Epoch: 12 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.329787 MAX=0.478207 MIN=0.253958
- [18/18] Loss: AVG=0.404024 MAX=0.631405 MIN=0.295426
Epoch: 12 Loss: 0.3669055137369368 MMD: 1.1483465780814488 BCE: 0.252070863213804 

Epoch: 13 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.332089 MAX=0.547858 MIN=0.229067
- [18/18] Loss: AVG=0.336915 MAX=0.452453 MIN=0.255870
Epoch: 13 Loss: 0.3345022226373355 MMD: 0.8459810101323657 BCE: 0.24990411930614048 

Epoch: 14 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.409032 MAX=0.650637 MIN=0.252861
- [18/18] Loss: AVG=0.348556 MAX=0.538211 MIN=0.287463
Epoch: 14 Loss: 0.378794069091479 MMD: 1.352464949919118 BCE: 0.2435475761691729 

Epoch: 15 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.436425 MAX=1.366332 MIN=0.224069
- [18/18] Loss: AVG=0.378509 MAX=0.669873 MIN=0.252804
Epoch: 15 Loss: 0.40746693313121796 MMD: 1.6727331206202507 BCE: 0.24019361949629253 

Epoch: 16 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.357742 MAX=0.898163 MIN=0.232278
- [18/18] Loss: AVG=0.398287 MAX=0.737381 MIN=0.258862
Epoch: 16 Loss: 0.3780146986246109 MMD: 1.226864183942477 BCE: 0.25532827691899407 

Epoch: 17 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.474004 MAX=0.768393 MIN=0.282107
- [18/18] Loss: AVG=0.406186 MAX=0.659594 MIN=0.259753
Epoch: 17 Loss: 0.4400950123866399 MMD: 1.8596448451280594 BCE: 0.25413053151634 

Epoch: 18 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.288877 MAX=0.465673 MIN=0.219457
- [18/18] Loss: AVG=0.334889 MAX=0.553721 MIN=0.262454
Epoch: 18 Loss: 0.31188292221890557 MMD: 0.746787299712499 BCE: 0.23720418827401268 

Epoch: 19 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.381931 MAX=0.651879 MIN=0.228405
- [18/18] Loss: AVG=0.452542 MAX=0.757233 MIN=0.241683
Epoch: 19 Loss: 0.41723667167954975 MMD: 1.8468349741564856 BCE: 0.23255317161480585 

Epoch: 20 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.348748 MAX=0.803888 MIN=0.217830
- [18/18] Loss: AVG=0.421565 MAX=0.846199 MIN=0.272497
Epoch: 20 Loss: 0.3851565793156624 MMD: 1.647581834759977 BCE: 0.22039839625358582 

Epoch: 21 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.347907 MAX=0.599759 MIN=0.232251
- [18/18] Loss: AVG=0.338106 MAX=0.550685 MIN=0.201724
Epoch: 21 Loss: 0.34300650904575986 MMD: 1.3390129274792142 BCE: 0.20910521927807066 

Epoch: 22 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.225101 MAX=0.262532 MIN=0.174295
- [18/18] Loss: AVG=0.292338 MAX=0.412129 MIN=0.194777
Epoch: 22 Loss: 0.2587193689412541 MMD: 0.7084984729687372 BCE: 0.18786952230665419 

Epoch: 23 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.235033 MAX=0.297204 MIN=0.185430
- [18/18] Loss: AVG=0.302972 MAX=0.667281 MIN=0.211841
Epoch: 23 Loss: 0.2690024466978179 MMD: 0.8041406762268808 BCE: 0.18858837833007178 

Epoch: 24 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.270138 MAX=0.363626 MIN=0.200930
- [18/18] Loss: AVG=0.322473 MAX=0.728976 MIN=0.213566
Epoch: 24 Loss: 0.29630521022611195 MMD: 0.992992045978705 BCE: 0.1970060078634156 

Epoch: 25 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.278682 MAX=0.445805 MIN=0.135231
- [18/18] Loss: AVG=0.316104 MAX=0.552803 MIN=0.185953
Epoch: 25 Loss: 0.29739314483271706 MMD: 1.2083591139978833 BCE: 0.17655723459190792 

Epoch: 26 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.286824 MAX=0.636199 MIN=0.164891
- [18/18] Loss: AVG=0.234760 MAX=0.415907 MIN=0.165114
Epoch: 26 Loss: 0.2607918572094705 MMD: 1.1073536227146785 BCE: 0.15005649460686576 

Epoch: 27 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.403311 MAX=0.982016 MIN=0.221667
- [18/18] Loss: AVG=0.214619 MAX=0.360648 MIN=0.125918
Epoch: 27 Loss: 0.3089652789963616 MMD: 1.704367636806435 BCE: 0.1385285117559963 

Epoch: 28 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.214554 MAX=0.379686 MIN=0.113563
- [18/18] Loss: AVG=0.201330 MAX=0.284816 MIN=0.133277
Epoch: 28 Loss: 0.2079417978723844 MMD: 0.8859062070647875 BCE: 0.11935117799374792 

Epoch: 29 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.178261 MAX=0.462309 MIN=0.088950
- [18/18] Loss: AVG=0.222174 MAX=0.386678 MIN=0.123240
Epoch: 29 Loss: 0.20021780994203356 MMD: 1.0062181444631682 BCE: 0.09959599417116907 

Epoch: 30 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.128143 MAX=0.197145 MIN=0.087036
- [18/18] Loss: AVG=0.201629 MAX=0.435726 MIN=0.104230
Epoch: 30 Loss: 0.1648859894937939 MMD: 0.7032136983341641 BCE: 0.09456461937063271 

Epoch: 31 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.164158 MAX=0.301149 MIN=0.063161
- [18/18] Loss: AVG=0.206912 MAX=0.632803 MIN=0.083574
Epoch: 31 Loss: 0.18553484314017826 MMD: 1.0954549180136786 BCE: 0.0759893496417337 

Epoch: 32 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.125150 MAX=0.190243 MIN=0.064924
- [18/18] Loss: AVG=0.175190 MAX=0.464209 MIN=0.080221
Epoch: 32 Loss: 0.1501698928574721 MMD: 0.7059989546736082 BCE: 0.0795699983007378 

Epoch: 33 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.177647 MAX=0.374657 MIN=0.067988
- [18/18] Loss: AVG=0.208448 MAX=0.343472 MIN=0.119819
Epoch: 33 Loss: 0.19304750404424137 MMD: 1.034278226395448 BCE: 0.08961968248089154 

Epoch: 34 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.213446 MAX=0.318823 MIN=0.100203
- [18/18] Loss: AVG=0.205685 MAX=0.418029 MIN=0.088070
Epoch: 34 Loss: 0.20956545944015184 MMD: 1.1557677015662193 BCE: 0.09398868762784535 

Epoch: 35 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.169954 MAX=0.454180 MIN=0.059191
- [18/18] Loss: AVG=0.204461 MAX=0.395805 MIN=0.072718
Epoch: 35 Loss: 0.187207434947292 MMD: 1.186471718053023 BCE: 0.068560263969832 

Epoch: 36 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.211954 MAX=0.835459 MIN=0.058216
- [18/18] Loss: AVG=0.170349 MAX=0.374332 MIN=0.082357
Epoch: 36 Loss: 0.1911518257111311 MMD: 1.3337423445449934 BCE: 0.0577775938436389 

Epoch: 37 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.130994 MAX=0.226148 MIN=0.061187
- [18/18] Loss: AVG=0.205457 MAX=0.731746 MIN=0.083341
Epoch: 37 Loss: 0.16822574970622858 MMD: 1.1557853511638112 BCE: 0.052647212934162885 

Epoch: 38 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.181230 MAX=0.704730 MIN=0.073626
- [18/18] Loss: AVG=0.163338 MAX=0.331104 MIN=0.060066
Epoch: 38 Loss: 0.1722838795847363 MMD: 1.1779864852627118 BCE: 0.05448523029271099 

Epoch: 39 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.192157 MAX=0.543707 MIN=0.060359
- [18/18] Loss: AVG=0.194229 MAX=0.363711 MIN=0.100089
Epoch: 39 Loss: 0.19319328500164878 MMD: 1.2585326077209578 BCE: 0.06734002588523759 

Epoch: 40 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.165228 MAX=0.257770 MIN=0.046264
- [18/18] Loss: AVG=0.148960 MAX=0.517704 MIN=0.068531
Epoch: 40 Loss: 0.1570940926257107 MMD: 1.1231487898363008 BCE: 0.04477921469757954 

Epoch: 41 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.151539 MAX=0.441810 MIN=0.040585
- [18/18] Loss: AVG=0.164868 MAX=0.367280 MIN=0.058483
Epoch: 41 Loss: 0.15820377402835423 MMD: 1.2230870806508594 BCE: 0.0358950641627113 

Epoch: 42 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.110298 MAX=0.377978 MIN=0.045191
- [18/18] Loss: AVG=0.105355 MAX=0.194908 MIN=0.043955
Epoch: 42 Loss: 0.1078264301435815 MMD: 0.8769572037789557 BCE: 0.020130711348934308 

Epoch: 43 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.192025 MAX=0.599401 MIN=0.037130
- [18/18] Loss: AVG=0.202814 MAX=0.427743 MIN=0.036870
Epoch: 43 Loss: 0.19741949666705397 MMD: 1.7887650653719902 BCE: 0.01854298755319582 

Epoch: 44 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.101213 MAX=0.430546 MIN=0.029270
- [18/18] Loss: AVG=0.098429 MAX=0.158538 MIN=0.026870
Epoch: 44 Loss: 0.09982119138456053 MMD: 0.8336645397875044 BCE: 0.016454738694139652 

Epoch: 45 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.056958 MAX=0.158911 MIN=0.026996
- [18/18] Loss: AVG=0.279712 MAX=0.917249 MIN=0.032320
Epoch: 45 Loss: 0.1683352387820681 MMD: 1.4939959363804922 BCE: 0.018935645206107035 

Epoch: 46 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.143283 MAX=0.278407 MIN=0.056663
- [18/18] Loss: AVG=0.131985 MAX=0.281350 MIN=0.028213
Epoch: 46 Loss: 0.13763386963142288 MMD: 1.24142447196775 BCE: 0.01349142201555272 

Epoch: 47 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.080837 MAX=0.272175 MIN=0.024829
- [18/18] Loss: AVG=0.092004 MAX=0.166883 MIN=0.044405
Epoch: 47 Loss: 0.08642039427326785 MMD: 0.7419609328111013 BCE: 0.012224302187355028 

Epoch: 48 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.126394 MAX=0.582793 MIN=0.030841
- [18/18] Loss: AVG=0.172667 MAX=0.415304 MIN=0.026201
Epoch: 48 Loss: 0.1495304847550061 MMD: 1.3683097519808345 BCE: 0.012699512350890372 

Epoch: 49 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.100071 MAX=0.259457 MIN=0.027220
- [18/18] Loss: AVG=0.178349 MAX=0.309495 MIN=0.026762
Epoch: 49 Loss: 0.13920994216783178 MMD: 1.2742543261912134 BCE: 0.011784508927828737 

Epoch: 50 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.104716 MAX=0.302427 MIN=0.029178
- [18/18] Loss: AVG=0.142312 MAX=0.641049 MIN=0.027310
Epoch: 50 Loss: 0.12351410287535852 MMD: 1.1234706681635644 BCE: 0.011167035231159793 
```

### Test(0.1)

```
0 0.3838383838383838 0.6347591362126246
0 0.7755909611579714 1.2823516975924774
0 1.1922576278246382 1.9357449752632117
0 1.6133102594035855 2.5905833396391484

Val set: BCE: 0.5484 Average f1: 40.3328% Average auc: 64.7646%
```