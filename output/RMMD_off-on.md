### Train

```
Origin: 1000 = 20 * 50 -> 2000 = 40 * 50 

K-fold: 18 * 50 + 36 * 50 -> 4 * 50 

Epoch: 1 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.916286 MAX=1.919662 MIN=0.425105
- [18/18] Loss: AVG=0.569076 MAX=0.801860 MIN=0.359243
Epoch: 1 Loss: 0.7426811854044596 MMD: 1.3475363734695647 BCE: 0.4057970841725667 

Epoch: 2 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.630535 MAX=1.427366 MIN=0.349729
- [18/18] Loss: AVG=0.409259 MAX=0.496809 MIN=0.313819
Epoch: 2 Loss: 0.5198974460363388 MMD: 0.8249479904770851 BCE: 0.31366044448481667 

Epoch: 3 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.496654 MAX=1.032638 MIN=0.341685
- [18/18] Loss: AVG=0.582816 MAX=1.316818 MIN=0.323523
Epoch: 3 Loss: 0.5397352625926336 MMD: 0.9251431491639879 BCE: 0.30844947033458286 

Epoch: 4 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.655884 MAX=1.700540 MIN=0.352084
- [18/18] Loss: AVG=0.545482 MAX=0.902665 MIN=0.349802
Epoch: 4 Loss: 0.6006826758384705 MMD: 1.1965180213252704 BCE: 0.3015531773368518 

Epoch: 5 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.808614 MAX=2.237197 MIN=0.351561
- [18/18] Loss: AVG=0.649296 MAX=1.390681 MIN=0.322304
Epoch: 5 Loss: 0.7289548897080951 MMD: 1.6984241985612445 BCE: 0.3043488413095474 

Epoch: 6 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.741676 MAX=1.610525 MIN=0.323384
- [18/18] Loss: AVG=0.489030 MAX=0.767003 MIN=0.322631
Epoch: 6 Loss: 0.6153529683748881 MMD: 1.2654465238253276 BCE: 0.2989913423856099 

Epoch: 7 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.593427 MAX=1.745435 MIN=0.304443
- [18/18] Loss: AVG=0.649016 MAX=1.456146 MIN=0.335306
Epoch: 7 Loss: 0.6212213701672025 MMD: 1.3076822608709335 BCE: 0.29430080784691703 

Epoch: 8 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.646090 MAX=1.891888 MIN=0.307183
- [18/18] Loss: AVG=0.378282 MAX=0.467323 MIN=0.306479
Epoch: 8 Loss: 0.5121855735778809 MMD: 0.9192150558034579 BCE: 0.2823818110757404 

Epoch: 9 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.525699 MAX=1.508349 MIN=0.336872
- [18/18] Loss: AVG=0.434746 MAX=0.703364 MIN=0.325988
Epoch: 9 Loss: 0.48022280136744183 MMD: 0.8200878517495261 BCE: 0.27520083801613915 

Epoch: 10 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.582851 MAX=1.140537 MIN=0.300563
- [18/18] Loss: AVG=0.641520 MAX=1.031675 MIN=0.284439
Epoch: 10 Loss: 0.6121851818429099 MMD: 1.3708178889420297 BCE: 0.2694807036055459 

Epoch: 11 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.434203 MAX=0.568661 MIN=0.311280
- [18/18] Loss: AVG=0.490512 MAX=0.959745 MIN=0.300225
Epoch: 11 Loss: 0.46235731575224137 MMD: 0.7875631948312124 BCE: 0.26546651952796513 

Epoch: 12 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.434737 MAX=0.789828 MIN=0.301180
- [18/18] Loss: AVG=0.460734 MAX=1.030050 MIN=0.267016
Epoch: 12 Loss: 0.44773539404074353 MMD: 0.7540552781687843 BCE: 0.2592215720150206 

Epoch: 13 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.665769 MAX=1.710152 MIN=0.317448
- [18/18] Loss: AVG=0.404129 MAX=0.888900 MIN=0.282789
Epoch: 13 Loss: 0.5349488159020742 MMD: 1.0902202385995123 BCE: 0.2623937560452355 

Epoch: 14 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.457228 MAX=0.981688 MIN=0.295309
- [18/18] Loss: AVG=0.521011 MAX=1.293967 MIN=0.310976
Epoch: 14 Loss: 0.48911962244245744 MMD: 0.9282691135174699 BCE: 0.25705234789186054 

Epoch: 15 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.369867 MAX=0.814105 MIN=0.252821
- [18/18] Loss: AVG=0.491368 MAX=0.820204 MIN=0.278471
Epoch: 15 Loss: 0.4306170774830712 MMD: 0.7243812026249038 BCE: 0.24952177703380585 

Epoch: 16 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.469520 MAX=1.752138 MIN=0.239739
- [18/18] Loss: AVG=0.441715 MAX=1.077117 MIN=0.279520
Epoch: 16 Loss: 0.4556174526611964 MMD: 0.8830988506476084 BCE: 0.23484273999929428 

Epoch: 17 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.542031 MAX=1.082431 MIN=0.262861
- [18/18] Loss: AVG=0.468267 MAX=0.838384 MIN=0.351899
Epoch: 17 Loss: 0.5051489853196673 MMD: 1.086024493806892 BCE: 0.23364286538627413 

Epoch: 18 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.329946 MAX=0.452554 MIN=0.271183
- [18/18] Loss: AVG=0.308168 MAX=0.390871 MIN=0.241252
Epoch: 18 Loss: 0.3190568536520004 MMD: 0.39636179473665023 BCE: 0.21996640413999557 

Epoch: 19 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.605836 MAX=1.663091 MIN=0.246618
- [18/18] Loss: AVG=0.499433 MAX=1.398574 MIN=0.244637
Epoch: 19 Loss: 0.5526346928543515 MMD: 1.3810338220662541 BCE: 0.20737623588906395 

Epoch: 20 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.367545 MAX=0.975079 MIN=0.210039
- [18/18] Loss: AVG=0.420158 MAX=0.743154 MIN=0.268063
Epoch: 20 Loss: 0.3938518762588501 MMD: 0.7473324371708764 BCE: 0.207018766966131 

Epoch: 21 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.310461 MAX=0.425483 MIN=0.219929
- [18/18] Loss: AVG=0.292334 MAX=0.344044 MIN=0.238943
Epoch: 21 Loss: 0.3013977093829049 MMD: 0.4163718397418658 BCE: 0.1973047513100836 

Epoch: 22 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.387656 MAX=0.623373 MIN=0.200612
- [18/18] Loss: AVG=0.402996 MAX=0.736175 MIN=0.198395
Epoch: 22 Loss: 0.3953262087371614 MMD: 0.8473057084613376 BCE: 0.1834997841053539 

Epoch: 23 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.262953 MAX=0.353567 MIN=0.178037
- [18/18] Loss: AVG=0.381699 MAX=0.558847 MIN=0.256830
Epoch: 23 Loss: 0.3223258985413445 MMD: 0.5678213826484151 BCE: 0.18037055391404364 

Epoch: 24 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.404037 MAX=0.680506 MIN=0.207327
- [18/18] Loss: AVG=0.440881 MAX=0.994995 MIN=0.220714
Epoch: 24 Loss: 0.422459134625064 MMD: 0.9973917255798975 BCE: 0.1731112011604839 

Epoch: 25 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.567261 MAX=0.986560 MIN=0.164688
- [18/18] Loss: AVG=0.317469 MAX=0.537615 MIN=0.210283
Epoch: 25 Loss: 0.442364734907945 MMD: 1.1726400173372693 BCE: 0.14920473098754883 

Epoch: 26 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.340819 MAX=1.236493 MIN=0.155145
- [18/18] Loss: AVG=0.372032 MAX=0.782645 MIN=0.166485
Epoch: 26 Loss: 0.35642525802055997 MMD: 0.8472151383757591 BCE: 0.14462147570318645 

Epoch: 27 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.248456 MAX=0.409459 MIN=0.182856
- [18/18] Loss: AVG=0.324115 MAX=0.817863 MIN=0.155037
Epoch: 27 Loss: 0.2862857836816046 MMD: 0.6154833982388178 BCE: 0.13241493494974244 

Epoch: 28 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.353587 MAX=1.041959 MIN=0.156735
- [18/18] Loss: AVG=0.457390 MAX=0.977851 MIN=0.211353
Epoch: 28 Loss: 0.40548844552702373 MMD: 1.138860285282135 BCE: 0.12077338165707058 

Epoch: 29 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.446449 MAX=1.147938 MIN=0.152165
- [18/18] Loss: AVG=0.276456 MAX=0.599659 MIN=0.151513
Epoch: 29 Loss: 0.3614521423975627 MMD: 1.0109643298718665 BCE: 0.10871105848087205 

Epoch: 30 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.353143 MAX=1.200563 MIN=0.149931
- [18/18] Loss: AVG=0.254250 MAX=0.427336 MIN=0.174214
Epoch: 30 Loss: 0.30369680954350364 MMD: 0.8131651836964819 BCE: 0.10040551424026489 

Epoch: 31 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.318953 MAX=0.650400 MIN=0.132518
- [18/18] Loss: AVG=0.359647 MAX=1.071688 MIN=0.119997
Epoch: 31 Loss: 0.3392997715208266 MMD: 1.032128321627776 BCE: 0.08126769359740946 

Epoch: 32 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.334414 MAX=1.139506 MIN=0.111858
- [18/18] Loss: AVG=0.187938 MAX=0.334059 MIN=0.122002
Epoch: 32 Loss: 0.26117611717846656 MMD: 0.7596793580386374 BCE: 0.07125627828968896 

Epoch: 33 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.321659 MAX=0.802609 MIN=0.115169
- [18/18] Loss: AVG=0.260303 MAX=0.409238 MIN=0.114404
Epoch: 33 Loss: 0.2909811246726248 MMD: 0.8624980060590638 BCE: 0.07535662439962228 

Epoch: 34 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.175405 MAX=0.269739 MIN=0.089806
- [18/18] Loss: AVG=0.398642 MAX=0.654735 MIN=0.145792
Epoch: 34 Loss: 0.28702365938160157 MMD: 0.9063058098157247 BCE: 0.06044720423718294 

Epoch: 35 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.254265 MAX=0.348670 MIN=0.078023
- [18/18] Loss: AVG=0.306303 MAX=1.096985 MIN=0.091658
Epoch: 35 Loss: 0.2802836286524932 MMD: 0.8919489946630266 BCE: 0.05729638019369708 

Epoch: 36 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.202410 MAX=0.419899 MIN=0.075181
- [18/18] Loss: AVG=0.266301 MAX=0.575661 MIN=0.096252
Epoch: 36 Loss: 0.23435545298788282 MMD: 0.6798564328087701 BCE: 0.06439134871794118 

Epoch: 37 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.238356 MAX=0.905389 MIN=0.093276
- [18/18] Loss: AVG=0.193866 MAX=0.632674 MIN=0.083438
Epoch: 37 Loss: 0.21611133052243126 MMD: 0.648854647245672 BCE: 0.053897665503124394 

Epoch: 38 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.200918 MAX=0.635038 MIN=0.076728
- [18/18] Loss: AVG=0.132950 MAX=0.179444 MIN=0.094587
Epoch: 38 Loss: 0.166933700028393 MMD: 0.47942426635159385 BCE: 0.04707763509617911 

Epoch: 39 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.227242 MAX=0.456782 MIN=0.070603
- [18/18] Loss: AVG=0.145831 MAX=0.208989 MIN=0.098851
Epoch: 39 Loss: 0.18653650995757845 MMD: 0.5832328854335679 BCE: 0.04072828663306104 

Epoch: 40 Learning Rate: 0.0001
- [9/18] Loss: AVG=0.266725 MAX=0.562694 MIN=0.078816
- [18/18] Loss: AVG=0.181882 MAX=0.501719 MIN=0.104540
Epoch: 40 Loss: 0.22430334695511395 MMD: 0.7199876118037436 BCE: 0.044306444107658334 

Epoch: 41 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.305359 MAX=0.663149 MIN=0.076847
- [18/18] Loss: AVG=0.332749 MAX=0.678422 MIN=0.057998
Epoch: 41 Loss: 0.31905412384205395 MMD: 1.1329309278064303 BCE: 0.035821389976061054 

Epoch: 42 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.121018 MAX=0.170532 MIN=0.082040
- [18/18] Loss: AVG=0.335267 MAX=1.124334 MIN=0.083857
Epoch: 42 Loss: 0.22814254504111078 MMD: 0.8096015776197115 BCE: 0.025742148152656026 

Epoch: 43 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.123160 MAX=0.253133 MIN=0.060332
- [18/18] Loss: AVG=0.225805 MAX=1.090966 MIN=0.059491
Epoch: 43 Loss: 0.17448260262608528 MMD: 0.6190219447016716 BCE: 0.019727117200899456 

Epoch: 44 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.122937 MAX=0.313164 MIN=0.046237
- [18/18] Loss: AVG=0.191353 MAX=0.671429 MIN=0.055970
Epoch: 44 Loss: 0.1571450394888719 MMD: 0.5681454994612269 BCE: 0.015108664028553499 

Epoch: 45 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.226508 MAX=0.649044 MIN=0.053473
- [18/18] Loss: AVG=0.142437 MAX=0.371791 MIN=0.055380
Epoch: 45 Loss: 0.1844724373271068 MMD: 0.6827867718206512 BCE: 0.013775743569971787 

Epoch: 46 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.143512 MAX=0.324806 MIN=0.064085
- [18/18] Loss: AVG=0.257308 MAX=0.633145 MIN=0.057351
Epoch: 46 Loss: 0.20040985321005186 MMD: 0.7472523657812012 BCE: 0.013596761350830397 

Epoch: 47 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.133663 MAX=0.372033 MIN=0.064882
- [18/18] Loss: AVG=0.339878 MAX=0.853841 MIN=0.048221
Epoch: 47 Loss: 0.23677051750322184 MMD: 0.8980911895632744 BCE: 0.012247715714491077 

Epoch: 48 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.312360 MAX=0.729353 MIN=0.051875
- [18/18] Loss: AVG=0.233807 MAX=0.521417 MIN=0.058097
Epoch: 48 Loss: 0.2730833796991242 MMD: 1.0479830536577437 BCE: 0.011087614835964309 

Epoch: 49 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.228488 MAX=0.474014 MIN=0.070349
- [18/18] Loss: AVG=0.141200 MAX=0.301427 MIN=0.059442
Epoch: 49 Loss: 0.18484371631509727 MMD: 0.7017897259857919 BCE: 0.00939628378384643 

Epoch: 50 Learning Rate: 1e-05
- [9/18] Loss: AVG=0.300332 MAX=1.261280 MIN=0.077710
- [18/18] Loss: AVG=0.249935 MAX=0.953080 MIN=0.079848
Epoch: 50 Loss: 0.2751338208715121 MMD: 1.048395264479849 BCE: 0.013035005682872402 
```

### Test

```
0 0.37894736842105264 0.6334296724470134
0 0.6768197088465846 1.225487047741383
0 0.9534154535274357 1.8077827358496967
0 1.2360241491796096 2.392960268338414

Val set: BCE: 0.6009 Average f1: 30.9006% Average auc: 59.8240%
```